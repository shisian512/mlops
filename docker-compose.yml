services:
  mlflow:
    image: ghcr.io/mlflow/mlflow:latest
    restart: always
    ports:
      - "5000:5000"
    volumes:
      - ./mlartifacts:/mlartifacts
      - ./mlruns:/mlruns
    command: >
      mlflow ui --host 0.0.0.0 --port 5000

  backend:
    build:
      context: .
      dockerfile: Dockerfile.fastapi
    image: mlops-backend:latest
    ports:
      - "8000:8000"
    env_file:
      - .env
    restart: always

  frontend:
    build:
      context: .
      dockerfile: Dockerfile.streamlit
    image: mlops-frontend:latest
    ports:
      - "8501:8501"
    env_file:
      - .env
    restart: always

  prometheus:
    image: prom/prometheus
    volumes:
      - ./prometheus:/etc/prometheus
    command:
    - '--config.file=/etc/prometheus/prometheus.yml'
    ports:
      - "9090:9090"
    restart: unless-stopped

  grafana:
    image: grafana/grafana
    ports:
      - "3000:3000"
    restart: always
    depends_on:
      - prometheus

  alertmanager:
    image: prom/alertmanager
    volumes:
      - ./alertmanager:/etc/alertmanager
    command:
      - '--config.file=/etc/alertmanager/config.yml'
      - '--storage.path=/alertmanager'
    ports:
      - "9093:9093"
    restart: unless-stopped
